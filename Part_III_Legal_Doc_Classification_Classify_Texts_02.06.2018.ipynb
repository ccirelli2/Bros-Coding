{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe purpose of this code is to classify legal text by type.\\n\\nTypes include:\\n1.) Complaint\\n2.) Order\\n3.) Summary judgement\\n4.) Cover sheet.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Part III Attempt to Classify the Complaint Files'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT STANDARD PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT MODULES FOR THIS PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\Chris.Cirelli\\\\Desktop\\\\Python Programming Docs\\\\GitHub\\\\Bros-Coding-master\\\\Bros-Coding')\n",
    "import Module_Part_II_Legal_Doc_Classification as mldc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE FILE LIST & PRE-CLASSIFIED TEXT OBJECTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''The purpose of this code is to define specific objects that will be used in the subsecuent code\n",
    "\n",
    "1.) List_of_txt_files  = List of files in directory\n",
    "2.) df_preClassified_text_file_class = A dataframe of the preclassified text with two columsn, the file name and class. \n",
    "'''\n",
    "\n",
    "os.chdir(r'I:\\Legal Analytics Sprint-S18\\Team Folders\\Team Wang\\Files Converted to Txt')\n",
    "Dir_list = os.listdir(r'I:\\Legal Analytics Sprint-S18\\Team Folders\\Team Wang\\Files Converted to Txt')\n",
    "List_of_txt_files = [file for file in Dir_list if '.txt' in file]\n",
    "df_preClassified_text = pd.read_excel('Text_Classification_Wang.xlsx')\n",
    "df_preClassified_text_File_Class = df_preClassified_text[['FILE', 'CLASS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A LIST OF THE KEY WORDS THAT YOU WILL LOOK FOR EACH IN EACH TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A TEXT CLASSIFIER USING ONLY THE WORD COMPLAINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Text_classifier_simple(List_preClassified_txt):\n",
    "    \n",
    "    # Import packages\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    from nltk import word_tokenize\n",
    "    \n",
    "    \n",
    "    # Import personal modules\n",
    "    os.chdir('C:\\\\Users\\\\Chris.Cirelli\\\\Desktop\\\\Python Programming Docs\\\\GitHub\\\\Bros-Coding-master\\\\Bros-Coding')\n",
    "    import Module_Part_II_Legal_Doc_Classification as mldc_pII\n",
    "    \n",
    "    # Change to Target_dir and define Dir_list\n",
    "    os.chdir(r'I:\\Legal Analytics Sprint-S18\\Team Folders\\Team Wang\\Files Converted to Txt')\n",
    "    Dir_list = os.listdir()\n",
    "    \n",
    "    # Create a Tuple of the File / Class columns.  Note to self, see if you can create this obj directly from pandas series\n",
    "    List_files = list(df_preClassified_text['FILE'])\n",
    "    List_files_short = List_files[:10]\n",
    "    List_class = list(df_preClassified_text['CLASS'])\n",
    "    List_class_short = List_class[:10]\n",
    "    Zip = list(zip(List_files_short, List_class_short))\n",
    "    \n",
    "    \n",
    "    Dict = {}\n",
    "    \n",
    "    # Iterate over list of files\n",
    "    for (x,y) in Zip:\n",
    "        \n",
    "        #Open and Read them into memory. \n",
    "        Open = open(x, 'rb')\n",
    "        Read = Open.read()\n",
    "        Str = str(Read.lower())\n",
    "        \n",
    "        # Clean Text & Tokenize (Probably should slice first, but whatever)\n",
    "        Clean_plus_Tokenize = mldc_pII.get_clean_text_using_text_clearning_pipeline(Str)\n",
    "        \n",
    "        \n",
    "        # Take first 200 Tokens \n",
    "        Slice_of_bread = Clean_plus_Tokenize[:200]\n",
    "        \n",
    "        # Serve Bread\n",
    "        print(x,y)\n",
    "        print(Slice_of_bread)\n",
    "        print(type(Slice_of_bread))\n",
    "        print('')\n",
    "        \n",
    "                           \n",
    "                           \n",
    "                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA_Northern_1_15-cv-04247-TWT_26.txt Order\n",
      "['document', 'filed', 'page', 'in', 'united', 'states', 'district', 'court', 'nfor', 'northern', 'district', 'georgia', 'michael', 'mosely', 'behalf', 'nhimself', 'similarly', 'situated', 'plaintiff', 'civil', 'action', 'twt', 'npittman', 'consultants', 'inc', 'georgia', 'llc', 'ndefendants', 'order', 'nthe', 'court', 'considered', 'defendant', 'motion', 'extension', 'time', 'xef', 'xac', 'response', 'plaintiff', 'motion', 'summary', 'judgment', 'nthe', 'court', 'hereby', 'grants', 'defendant', 'motion', 'deadline', 'xef', 'xac', 'response', 'stated', 'case', 'october', 'order', 'entered', 'day', 'day', 'october', 'thrash', 'thomas', 'thrash', 'judge', 'united', 'states', 'district', 'court', 'northern', 'district', 'georgia']\n",
      "<class 'list'>\n",
      "\n",
      "GA_Northern_1_15-cv-04247-TWT_32.txt Order\n",
      "['case', 'document', 'filed', 'page', 'in', 'united', 'states', 'district', 'court', 'nfor', 'northern', 'district', 'georgia', 'atlanta', 'division', 'michael', 'mosley', 'on', 'behalf', 'similarly', 'situated', 'plaintiff', 'civil', 'action', 'file', 'npittman', 'consultants', 'georgia', 'limited', 'liability', 'company', 'ndefendants', 'opinion', 'order', 'nthis', 'action', 'fair', 'labor', 'standards', 'act', 'recovery', 'nof', 'unpaid', 'overtime', 'minimum', 'wages', 'court', 'plaintiffs', 'motion', 'partial', 'summary', 'udgment', 'doc', 'reasons', 'set', 'forth', 'nplaintiffs', 'motion', 'partial', 'summary', 'udgment', 'doc', 'granted', 'part', 'ndenied', 'part', 'orders', 'mosley', 'document', 'filed', 'page', 'nthe', 'plaintiffs', 'georgia', 'construction', 'workers', 'hired', 'defendant', 'pittman', 'consultants', 'general', 'contracting', 'corporation', 'located', 'georgia', 'travel', 'covington', 'kentucky', 'work', 'construction', 'project', 'september', 'march', 'plaintiffs', 'hold', 'special', 'licenses', 'ncertificates', 'experienced', 'painters', 'prior', 'traveling', 'kentucky', 'plaintiffs', 'completed', 'employment', 'applications', 'pittman', 'plaintiffs', 'transported', 'basic', 'equipment', 'paint', 'brushes', 'nladders', 'drills', 'wrenches', 'pittman', 'consultants', 'provided', 'speciality', 'equipment', 'including', 'safety', 'harnesses', 'sprayer', 'tips', 'hard', 'addition', 'court', 'draws', 'material', 'facts', 'almost', 'entirely', 'plaintiffs', 'statement', 'undisputed', 'material', 'facts', 'xef', 'xac', 'local', 'rule', 'defendants', 'required', 'submit', 'response', 'plaintiffs', 'statement', 'undisputed', 'material', 'facts', 'defendants', 'failed', 'result', 'nthe', 'court', 'deem', 'plaintiffs', 'asserted', 'facts', 'admitted', 'pls', 'statement', 'facts', 'compl', 'pittman', 'pls', 'statement', 'facts', 'lil', 'xef', 'xac', 'orders', 'mosley', 'document', 'filed', 'page', 'money', 'indeed', 'plaintiffs', 'control', 'ntasks', 'hiring', 'workers', 'activities', 'normally', 'associated', 'running', 'independent', 'thus', 'court', 'finds', 'factor', 'points', 'toward', 'employee', 'third', 'although', 'plaintiffs', 'invested', 'certain', 'tools', 'like', 'paint', 'nbrushes', 'ladders', 'drills', 'pittman', 'consultants', 'investments', 'outweigh', 'plaintiffs', 'as', 'previously', 'noted', 'pittman', 'consultants', 'provided', 'additional', 'equipment', 'nto', 'transport', 'equipment', 'transportation', 'work', 'site', 'hotel', 'lodging', 'moreover', 'pittman', 'consultants', 'could', 'employ', 'additional', 'workers', 'result', 'factor', 'weighs', 'favor', 'employee', 'status', 'fourth', 'plaintiffs', 'jobs', 'require', 'special', 'licenses', 'certifications', 'plaintiffs', 'skilled', 'painters', 'mosley', 'xef', 'xac', 'scantland', 'finding', 'plaintiffs', 'little', 'opportunity', 'profit', 'inter', 'alia', 'negotiate', 'otherwise', 'determine', 'rates', 'paid', 'jobs', 'earn', 'additional', 'income', 'initiative', 'limited', 'xef', 'xac', 'demers', 'adams', 'homes', 'northwest', 'homes', 'paid', 'nfor', 'maj', 'ority', 'demers', 'supplies', 'including', 'utilities', 'telephone', 'model', 'home', 'well', 'demers', 'pager', 'mls', 'fees', 'board', 'membership']\n",
      "<class 'list'>\n",
      "\n",
      "GA_Northern_1_15-cv-04249-ODE_4.txt Civil Cover Sheet\n",
      "['case', 'ode', 'document', 'filed', 'xef', 'xac', 'rev', 'ndga', 'civil', 'cover', 'shelt', 'nthe', 'civil', 'cover', 'sheet', 'information', 'contained', 'herein', 'either', 'replace', 'supplement', 'xef', 'xac', 'service', 'piendings', 'papers', 'required', 'law', 'except', 'nprovided', 'local', 'rules', 'court', 'form', 'required', 'use', 'clerk', 'court', 'purpose', 'initiating', 'civil', 'docket', 'record', 'see', 'instructions', 'attached', 'plaintiff', 'defendanhs', 'xef', 'xac', 'xef', 'xac', 'xef', 'xac', 'wqlk', 'xef', 'xac', 'mwiqwwnl', 'county', 'resid', 'owrst', 'listed', 'county', 'residence', 'first', 'listed', 'plaintiff', 'defendant', 'except', 'plaintiff', 'cases', 'plaintiff', 'cases', 'note', 'land', 'condemnation', 'cases', 'use', 'location', 'tract', 'land', 'involved', 'am', 'dress', 'telephone', 'numbew', 'attorneys', 'known', 'address', 'ii', 'basis', 'urisdiction', 'iii', 'citizenship', 'principal', 'parties', 'place', 'one', 'box', 'place', 'one', 'box', 'plaintiff', 'one', 'box', 'defendant', 'diversity', 'cases', 'nrm', 'def', 'plf', 'def', 'government', 'xef', 'xac', 'federal', 'question', 'citizen', 'state', 'incorporated', 'principal', 'plaintiff', 'government', 'party', 'place', 'business', 'state', 'government', 'diversity', 'citizen', 'another', 'stated', 'incorporated', 'principal', 'defendant', 'indicate', 'citizenship', 'parties', 'place', 'business', 'another', 'in', 'sun', 'citizen', 'subject', 'foreign', 'country', 'foreign', 'nation', 'iv', 'origin', 'place', 'one', 'box', 'ntransferred', 'appeal', 'district', 'judge', 'el', 'original', 'removed', 'remanded', 'reinstated', 'another', 'district', 'multidistrict', 'magistrate', 'judge', 'proceeding', 'state', 'court', 'appellate', 'cour', 'spe', 'diff', 'district', 'litigation', 'judgment', 'cause', 'action', 'cite', 'civil', 'statute', 'filing', 'write', 'brief', 'statement', 'cause', 'xbb', 'cite', 'jurisdictional', 'statutes', 'unless', 'diversity', 'xef', 'xac', 'de', 'xef', 'xac', 'tdb', 'gammy', 'nbouf', 'xef', 'xac', 'xef', 'xac', 'complex', 'check', 'reason', 'unusually', 'large', 'umber', 'parties', 'problems', 'locating', 'preserving', 'evidence', 'unusually', 'large', 'umber', 'claims', 'defenses', 'pending', 'parallel', 'investigations', 'actions', 'government', 'factual', 'issues', 'exceptionally', 'complex', 'multipie', 'use', 'experts', 'greater', 'normal', 'volume', 'evidence', 'need', 'discovery', 'outside', 'united', 'states', 'boundaries', 'extended', 'discovery', 'period', 'needed', 'existence', 'highly', 'technical', 'issues', 'proof', 'ncqntinued', 'reverse', 'nifor', 'office', 'use', 'xef', 'xac', 'magjudge', 'yingifp']\n",
      "<class 'list'>\n",
      "\n",
      "GA_Northern_1_15-cv-04258-AT_0.txt Compliant\n",
      "[]\n",
      "<class 'list'>\n",
      "\n",
      "GA_Northern_1_15-cv-04260-CC_0.txt Compliant\n",
      "['case', 'document', 'filed', 'page', 'in', 'united', 'states', 'district', 'court', 'northern', 'district', 'georgia', 'atlanta', 'division', 'dante', 'bryant', 'plaintiff', 'first', 'data', 'corporation', 'defendant', 'demand', 'ury', 'trial', 'nvvvvvvvvvvvvv', 'complaint', 'ncomes', 'plaintiff', 'dante', 'bryant', 'hereinafter', 'bryant', 'files', 'complaint', 'defendant', 'first', 'data', 'corporation', 'hereinafter', 'data', 'shows', 'court', 'as', 'follows', 'nature', 'complaint', 'nthis', 'action', 'damages', 'discrimination', 'based', 'race', 'violation', 'title', 'vii', 'civil', 'rights', 'act', 'seq', 'amended', 'nthe', 'civil', 'rights', 'act', 'vii', 'violation', 'ofcase', 'document', 'filed', 'page', 'nthe', 'age', 'discrimination', 'employment', 'act', 'well', 'state', 'federal', 'law', 'claims', 'attorney', 'fees', 'ii', 'urisdiction', 'venue', 'nthe', 'jurisdiction', 'court', 'invoked', 'pursuant', 'sections', 'personal', 'jurisdiction', 'venue', 'appropriate', 'pursuant', 'as', 'defendant', 'located', 'northern', 'district', 'georgia', 'atlanta', 'division', 'nthe', 'unlawful', 'conduct', 'complained', 'herein', 'occurred', 'district', 'division', 'iii', 'parties', 'at', 'times', 'relevant', 'action', 'plaintiff', 'employee', 'first', 'data', 'corporation', 'plaintiff', 'dante', 'bryant', 'individual', 'residing', 'sandy', 'springs', 'georgia', 'nwhich', 'fulton', 'county', 'complaint', 'plaintiff', 'bryant', 'an', 'employee', 'defendant', 'first', 'data', 'corporation', 'location', 'employment', 'within', 'jurisdiction', 'court', 'plaintiff', 'bryant', 'employee', 'defined', 'title', 'vii', 'civil', 'rights', 'document', 'filed', 'page', 'count', 'lig', 'uidated', 'nthe', 'allegations', 'contained', 'paragraphs', 'incorporated', 'herein', 'reference', 'nthe', 'defendant', 'discriminatory', 'act', 'willful', 'within', 'meaning', 'nadea', 'plaintiff', 'entitled', 'liquidated', 'damages', 'count', 'attorney', 'fees', 'nthe', 'allegations', 'contained', 'paragraphs', 'incorporated', 'herein', 'reference', 'plaintiff', 'entitled', 'award', 'attorney', 'fees', 'expenses', 'litigation', 'on', 'every', 'cause', 'action', 'alleged', 'herein', 'defendant', 'acted', 'in', 'bad', 'faith', 'stubbornly', 'litigious', 'caused', 'plaintiff', 'unnecessary', 'trouble', 'nand', 'expense', 'wherefore', 'plaintiff', 'respectfully', 'requests', 'following', 'relief', 'afford', 'plaintiff', 'trial', 'jury', 'issues', 'triable', 'award', 'plaintiff', 'lost', 'wages', 'date', 'termination', 'date', 'nof', 'judgment', 'document', 'filed', 'page', 'award', 'plaintiff', 'liquidated', 'damages', 'amount', 'equal', 'lost', 'wages', 'nfrom', 'date', 'termination', 'date', 'ofjudgment', 'award', 'plaintiff', 'compensatory', 'damages', 'injuries', 'nsuffered', 'result', 'defendants', 'unlawful', 'acts', 'award', 'plaintiff', 'punitive', 'damages', 'order', 'deter', 'future', 'unlawful', 'conduct', 'by', 'defendant', 'deem', 'plaintiff', 'prevailing', 'party', 'award', 'attorneys', 'fees', 'expenses', 'nof', 'litigation', 'award', 'plaintiff', 'interest', 'award', 'plaintiff', 'equitable', 'monetary', 'relief', 'court', 'deems', 'nand', 'proper', 'including', 'reinstatement', 'reformation']\n",
      "<class 'list'>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA_Northern_1_15-cv-04260-CC_8.txt Summary\n",
      "['document', 'filed', 'page', 'in', 'united', 'states', 'district', 'court', 'nfor', 'northern', 'district', 'georgia', 'atlanta', 'division', 'dante', 'bryant', 'plaintiff', 'civil', 'action', 'file', 'first', 'data', 'corporation', 'defendant', 'magistrate', 'judge', 'scheduling', 'order', 'instructions', 'nregarding', 'summary', 'judgment', 'motions', 'on', 'march', 'parties', 'filed', 'joint', 'preliminary', 'report', 'discovery', 'plan', 'doc', 'time', 'limits', 'adding', 'parties', 'amending', 'npleadings', 'filing', 'motions', 'discussing', 'settlement', 'stated', 'joint', 'preliminary', 'report', 'discovery', 'plan', 'action', 'set', 'trial', 'ndispositive', 'motions', 'ruled', 'provided', 'claims', 'remain', 'disposition', 'nthe', 'discovery', 'period', 'ends', 'july', 'notice', 'regarding', 'summary', 'judgment', 'motions', 'nyou', 'hereby', 'notified', 'within', 'days', 'date', 'motion', 'summary', 'judgment', 'served', 'upon', 'opposing', 'party', 'must', 'file', 'nmaterials', 'including', 'affidavits', 'depositions', 'answers', 'interrogatories', 'nadmissions', 'file', 'relevant', 'materials', 'wish', 'becase', 'document', 'filed', 'page', 'considered', 'opposition', 'motion', 'summary', 'judgment', 'federal', 'rules', 'civil', 'procedure', 'rule', 'local', 'rule', 'ndga', 'moore', 'state', 'florida', 'cir', 'nyou', 'also', 'notified', 'unless', 'otherwise', 'stated', 'trial', 'court', 'court', 'will', 'take', 'motion', 'summary', 'judgment', 'advisement', 'immediately', 'upon', 'nthe', 'expiration', 'period', 'may', 'rule', 'upon', 'anytime', 'thereafter', 'absent', 'unusual', 'circumstances', 'hearing', 'scheduled', 'consideration', 'nthe', 'motion', 'moore', 'xef', 'xac', 'donaldson', 'clark', 'cir', 'griffith', 'wainwright', 'cir', 'nthe', 'entry', 'summary', 'judgment', 'trial', 'court', 'xef', 'xac', 'judgment', 'claim', 'claims', 'decided', 'finn', 'gunter', 'cir', 'nwhenever', 'nonmoving', 'party', 'bears', 'burden', 'proof', 'trial', 'dispositive', 'issue', 'party', 'moving', 'summary', 'judgment', 'demonstrated', 'absence', 'nof', 'genuine', 'issue', 'fact', 'nonmoving', 'party', 'must', 'beyond', 'pleadings', 'nand', 'must', 'designate', 'affidavit', 'materials', 'facts', 'showing', 'there', 'genuine', 'issue', 'trial', 'fed', 'civ', 'celotex', 'catrett', 'document', 'filed', 'page', 're', 'uirements', 'summary', 'udgment', 'motions', 'statement', 'undisputed', 'material', 'facts', 'nwhenever', 'motion', 'summary', 'judgment', 'filed', 'must', 'accompanied', 'by', 'separate', 'concise', 'numbered', 'statement', 'material', 'facts', 'nmovant', 'contends', 'genuine', 'issue', 'tried', 'ndga', 'material', 'fact', 'must', 'numbered', 'separately', 'supported', 'citation', 'evidence', 'proving', 'fact', 'court', 'consider', 'fact', 'supported', 'by', 'citation', 'evidence', 'including', 'page', 'paragraph', 'umber', 'supported', 'citation', 'pleading', 'rather', 'evidence', 'stated', 'issue', 'legal', 'conclusion', 'set', 'brief', 'movant', 'statement', 'undisputed', 'facts', 'nthe', 'party', 'shall', 'file', 'response', 'moving', 'party', 'statement', 'nof', 'undisputed']\n",
      "<class 'list'>\n",
      "\n",
      "GA_Northern_1_15-cv-04264-AT_0.txt Compliant\n",
      "[]\n",
      "<class 'list'>\n",
      "\n",
      "GA_Northern_1_15-cv-04281-RWS_0.txt Compliant\n",
      "['document', 'filed', 'page', 'in', 'united', 'states', 'district', 'court', 'nfor', 'northern', 'district', 'georgia', 'atlanta', 'division', 'mickey', 'jacobs', 'plaintiff', 'civil', 'action', 'file', 'nvs', 'recreational', 'equipment', 'rei', 'ury', 'trial', 'demand', 'defendant', 'complaint', 'ncomes', 'plaintiff', 'hereby', 'files', 'complaint', 'showing', 'nthe', 'following', 'plaintiff', 'resident', 'georgia', 'defendant', 'recreational', 'equipment', 'rei', 'foreign', 'corporation', 'conducts', 'business', 'cobb', 'county', 'defendant', 'may', 'nserved', 'summons', 'complaint', 'upon', 'registered', 'agent', 'corporate', 'creations', 'network', 'gordy', 'parkway', 'lst', 'floor', 'nmarietta', 'georgia', 'document', 'filed', 'page', 'urisdiction', 'venue', 'proper', 'action', 'plaintiff', 'denied', 'employment', 'defendant', 'based', 'age', 'nand', 'disability', 'defendant', 'agent', 'mike', 'conducted', 'telephone', 'interview', 'plaintiff', 'december', 'customer', 'service', 'specialist', 'position', 'defendant', 'agent', 'mike', 'asked', 'plaintiff', 'several', 'questions', 'nregarding', 'experience', 'discussed', 'rate', 'pay', 'plaintiff', 'would', 'nreceiving', 'well', 'plaintiff', 'schedule', 'defendant', 'scheduled', 'face', 'face', 'group', 'interview', 'plaintiff', 'on', 'anuary', 'mike', 'advised', 'plaintiff', 'alarmed', 'everyone', 'nhad', 'group', 'document', 'filed', 'page', 'nwhen', 'plaintiff', 'arrived', 'face', 'face', 'group', 'interview', 'plaintiff', 'oldest', 'person', 'well', 'one', 'noticeable', 'disability', 'defendant', 'agents', 'prevented', 'plaintiff', 'securing', 'employment', 'nwith', 'defendant', 'defendant', 'actions', 'denied', 'plaintiff', 'employment', 'right', 'make', 'enforce', 'contracts', 'employment', 'violation', 'age', 'discrimination', 'employment', 'act', 'amended', 'net', 'seq', 'hereinafter', 'adea', 'provisions', 'americans', 'nwith', 'disabilities', 'act', 'defendant', 'actions', 'denying', 'plaintiff', 'employment', 'right', 'make', 'enforce', 'employment', 'contracts', 'willful', 'retaliatory', 'wanton', 'intentional', 'malicious', 'defendant', 'injured', 'plaintiff', 'caused', 'damages', 'including', 'limited', 'training', 'lost', 'wages', 'npromotions', 'benefits', 'pain', 'suffering', 'document', 'filed', 'page', 'wherefore', 'plaintiff', 'respectfully', 'prays', 'judgment', 'ndefendants', 'follows', 'defendants', 'ordered', 'hire', 'plaintiff', 'suitable', 'position', 'defendants', 'ordered', 'pay', 'compensatory', 'punitive', 'damages', 'plaintiff', 'plaintiff', 'recover', 'reasonable', 'attorneys', 'fees', 'relief', 'court', 'deems', 'proper', 'jury', 'demand', 'plaintiff', 'hereby', 'request', 'trial', 'jury', 'issues', 'action', 'nthis', 'day', 'december', 'npankey', 'horlock', 'llc', 'by', 'pankey', 'nlarry', 'pankey', 'georgia', 'bar', 'nattorneys', 'plaintiff', 'dunwoody', 'village', 'parkway', 'suite', 'atlanta', 'georgia', 'phone', 'fax', 'nlpankey', 'document', 'filed', 'page', 'certification', 'font', 'size', 'pursuant', 'local', 'rule', 'local', 'rules', 'united', 'states', 'district', 'court', 'northern', 'district', 'georgia', 'larry', 'pankey', 'nof', 'pankey', 'horlock', 'llc', 'attorney', 'plaintiff', 'mickey', 'acobs', 'hereby']\n",
      "<class 'list'>\n",
      "\n",
      "GA_Northern_1_15-cv-04284-WSD_0.txt Compliant\n",
      "['document', 'filed', 'page', 'in', 'united', 'states', 'district', 'court', 'nfor', 'northern', 'district', 'georgia', 'atlanta', 'division', 'nangela', 'foye', 'plaintiff', 'civil', 'action', 'file', 'ury', 'trial', 'demand', 'hanger', 'prosthetics', 'northotics', 'defendant', 'complaint', 'ncomes', 'plaintiff', 'submits', 'complaint', 'defendant', 'based', 'following', 'allegations', 'parties', 'urisdiction', 'venue', 'nthis', 'action', 'brought', 'provisions', 'title', 'vii', 'civil', 'rights', 'act', 'amended', 'seq', 'hereinafter', 'vii', 'seeking', 'remedy', 'race', 'discrimination', 'harassment', 'retaliation', 'loci', 'provisions', 'americans', 'disabilities', 'act', 'xef', 'xac', 'hereinafter', 'seeking', 'remedy', 'discrimination', 'employment', 'occurring', 'plaintiff', 'employed', 'document', 'filed', 'page', 'plaintiff', 'resident', 'state', 'georgia', 'times', 'material', 'employment', 'defendant', 'defendant', 'foreign', 'corporation', 'business', 'state', 'georgia', 'defendant', 'hanger', 'prosthetics', 'orthotics', 'principal', 'address', 'domain', 'drive', 'suite', 'austin', 'defendant', 'may', 'served', 'upon', 'registered', 'agent', 'service', 'process', 'corporation', 'service', 'company', 'technology', 'parkway', 'south', 'norcross', 'georgia', 'jurisdiction', 'claims', 'complaint', 'conferred', 'pursuant', 'urisdiction', 'venue', 'proper', 'judicial', 'district', 'factual', 'allegations', 'defendant', 'hired', 'plaintiff', 'uly', 'office', 'document', 'filed', 'page', 'in', 'march', 'plaintiff', 'supervisor', 'matthew', 'nelson', 'advised', 'plaintiff', 'transferring', 'sandy', 'springs', 'office', 'plaintiff', 'supervisor', 'nelson', 'advised', 'wanted', 'place', 'handicapped', 'worker', 'plaintiff', 'position', 'worker', 'would', 'relate', 'better', 'nthe', 'patients', 'on', 'march', 'plaintiff', 'transferred', 'sandy', 'nsprings', 'office', 'plaintiff', 'ever', 'received', 'proper', 'training', 'supervisor', 'adriane', 'hill', 'plaintiff', 'also', 'noticed', 'employees', 'logging', 'employee', 'names', 'violation', 'company', 'policies', 'plaintiff', 'brought', 'violation', 'terry', 'hobby', 'document', 'filed', 'page', 'plaintiff', 'concerns', 'addressed', 'violations', 'continued', 'after', 'plaintiff', 'complained', 'five', 'days', 'later', 'plaintiff', 'written', 'up', 'complaints', 'nthe', 'plaintiff', 'asked', 'see', 'documentation', 'however', 'information', 'not', 'placed', 'file', 'due', 'incident', 'transpired', 'plaintiff', 'job', 'plaintiff', 'stress', 'well', 'mental', 'health', 'assessment', 'nthe', 'plaintiff', 'advised', 'supervisor', 'angela', 'hazard', 'condition', 'defendant', 'terminated', 'plaintiff', 'three', 'days', 'later', 'september', 'document', 'filed', 'page', 'race', 'discrimination', 'harassment', 'retaliation', 'title', 'vii', 'plaintiff', 'respectfully', 'reincorporates', 'allegations', 'contained', 'nparagraphs', 'plaintiff', 'african', 'american', 'former', 'employee', 'defendant', 'defendant', 'discriminated', 'harassed', 'plaintiff', 'basis', 'nher', 'race', 'violation', 'title', 'vii', 'defendant', 'retaliated', 'plaintiff', 'engaging', 'protected', 'activity', 'violation', 'title', 'vii', 'defendant', 'treatment', 'plaintiff', 'motivated', 'plaintiff', 'racial', 'characteristics', 'amounts', 'race', 'discrimination', 'document', 'filed', 'page']\n",
      "<class 'list'>\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GA_Northern_1_15-cv-04285-AT_0.txt Compliant\n",
      "[]\n",
      "<class 'list'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Text_classifier_simple(df_preClassified_text_File_Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A TEXT CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Text_classification_function(List_txt_files, List_preClassified_txt):\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A FUNCTION FOR FORM THE LIST OF TEXT BY GROUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_list_by_group(Excel_doc):\n",
    "    '''\n",
    "    Input   = Excel Doc\n",
    "    Output  = Dataframe of a single file group. \n",
    "    '''\n",
    "    \n",
    "    # Create a Dictionary to capture class names & files\n",
    "    \n",
    "    Dict_classes_files = {}\n",
    "    \n",
    "    # Create Dataframe in memory\n",
    "    df = pd.read_excel(Excel_doc)\n",
    "    \n",
    "    # Limit to File & Class\n",
    "    df_file_class = df[['FILE','CLASS']]\n",
    "    \n",
    "    # Create list of classes\n",
    "    List_file_classes = list(set(df_file_class['CLASS']))\n",
    "\n",
    "    # Loop over class list to obtan\n",
    "    \n",
    "    for Class in List_file_classes:\n",
    "        Def_class = df_file_class['CLASS'] == Class \n",
    "        Limit_df = df_file_class[Def_class]\n",
    "        Dict_classes_files[Class] = Limit_df['FILE']\n",
    "        \n",
    "    return Dict_classes_files\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE MASTER DATAFRAME FROM INDIVIDUAL CLASS WORD DISTRIBUTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_code_classify_texts_word_freq():\n",
    "    \n",
    "    # Import Packages\n",
    "    import nltk\n",
    "    import os\n",
    "    import pandas as pd\n",
    "    \n",
    "    # Import Personal Modules\n",
    "    os.chdir('C:\\\\Users\\\\Chris.Cirelli\\\\Desktop\\\\Python Programming Docs\\\\GitHub\\\\Bros-Coding-master\\\\Bros-Coding')\n",
    "    import Module_Legal_Doc_Classification as mldc\n",
    "    \n",
    "    # Change to the target directory\n",
    "    os.chdir(r'I:\\Legal Analytics Sprint-S18\\Team Folders\\Team Wang\\Files Converted to Txt')\n",
    "    Dir_list = os.listdir(r'I:\\Legal Analytics Sprint-S18\\Team Folders\\Team Wang\\Files Converted to Txt')\n",
    "    \n",
    "    # Create a list of unique tokens from the clean concatenated text file\n",
    "    List_uniqueTokens = mldc.get_list_uniqueTokens_from_cleaned_concat_text()\n",
    "    \n",
    "    # Create the base dataframe with the index as the set of unique tokens/words\n",
    "    dataframe_unique_tokens = mldc.get_dataframe_unique_tokens(List_uniqueTokens)\n",
    "    \n",
    "    # Define Excel doc where pre-classisified files are located\n",
    "    Excel_file = 'Text_Classification_Wang.xlsx'\n",
    "    \n",
    "    # Create a dictionary whose keys are the file classes and values the files for each group. \n",
    "    Dict_files_by_class = create_file_list_by_group(Excel_file)\n",
    "    \n",
    "    # Create a Master Dataframe to house final values\n",
    "    Master_dataframe = pd.DataFrame({}, index = list(dataframe_unique_tokens.index))\n",
    "    \n",
    "    # Loop over the dictionary keys\n",
    "    for Class in Dict_files_by_class.keys():\n",
    "        \n",
    "        # Create a list of the files\n",
    "        File_list = list(Dict_files_by_class[Class])\n",
    "        \n",
    "        # Feed each class list trough the word counter\n",
    "        df_single_class_word_count = get_frequencyDist_legal_text(File_list, dataframe_unique_tokens)\n",
    "        \n",
    "        # Merge individual text file columns into one percentage for the given class\n",
    "        df_merged_columns = Merge_dataframe_columns_calc_percentage(Class, df_single_class_word_count)\n",
    "        \n",
    "        # Merge individual dataframes into master dataframe\n",
    "        Master_dataframe[Class] = df_merged_columns[Class]\n",
    "        \n",
    "    # Return the Master Dataframe with the word % for all classes. \n",
    "    return Master_dataframe       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_dataframe_unique_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-194f8223bedc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal_code_classify_texts_word_freq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-f856908d9205>\u001b[0m in \u001b[0;36mfinal_code_classify_texts_word_freq\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# Create the base dataframe with the index as the set of unique tokens/words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mdataframe_unique_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_dataframe_unique_tokens\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList_uniqueTokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Define Excel doc where pre-classisified files are located\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_dataframe_unique_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "Test = final_code_classify_texts_word_freq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Final Reprot</th>\n",
       "      <th>Order</th>\n",
       "      <th>Compliant</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Civil Cover Sheet</th>\n",
       "      <th>Junk</th>\n",
       "      <th>Motion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>scrutinized</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bagby</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coim</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cam</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.010204</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hammond</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Final Reprot     Order  Compliant   Summary  Civil Cover Sheet  \\\n",
       "scrutinized          0.00  0.000000   0.000000  0.000000           0.000000   \n",
       "bagby                0.25  0.030303   0.011236  0.011111           0.010309   \n",
       "coim                 0.00  0.000000   0.000000  0.000000           0.000000   \n",
       "cam                  0.00  0.000000   0.000000  0.000000           0.010309   \n",
       "hammond              0.00  0.000000   0.000000  0.000000           0.000000   \n",
       "\n",
       "                 Junk  Motion  \n",
       "scrutinized  0.000000    0.00  \n",
       "bagby        0.010204    0.01  \n",
       "coim         0.000000    0.00  \n",
       "cam          0.010204    0.01  \n",
       "hammond      0.000000    0.00  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the Master Dataframe to Excel_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Import Personal Modules\n",
    "os.chdir('C:\\\\Users\\\\Chris.Cirelli\\\\Desktop\\\\Python Programming Docs\\\\GitHub\\\\Bros-Coding-master\\\\Bros-Coding')\n",
    "import Module_Legal_Doc_Classification as mldc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Master Dataframe to Excel \n",
    "os.chdir(r'I:\\Legal Analytics Sprint-S18\\Team Folders\\Team Wang\\Files Converted to Txt')\n",
    "mldc.write_to_excel(Test, 'Master Word Dist Dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
